{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Bases\n",
    "import keras as k\n",
    "import tensorflow as tf\n",
    "\n",
    "## data\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "## building\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, LayerNormalization, GlobalAveragePooling2D\n",
    "\n",
    "## plotting\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## callbacks\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "from keras.applications import ResNet152\n",
    "from keras import Input, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Configuration for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPU, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "memory_limit=1024\n",
    "if gpus:\n",
    "  # Create 2 virtual GPUs with 1GB memory each\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit),\n",
    "         #tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit),\n",
    "         tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4093476482208990596\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4050526615020432687\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3034185728\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6871143520370017842\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4045811008313762940\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has the following directory ***structure***:\n",
    "\n",
    "<pre>\n",
    "<b>Fruit Images Dataset</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>Apple Braeburn</b>: [0_100.jpg, ..]\n",
    "    |______ <b>Apple Crimson Snow</b>: [0_100.jpg, ..] \n",
    "    ..\n",
    "    |______ <b>Apple Watermelon</b>: [0_100.jpg, ..]\n",
    "|__ <b>test</b>\n",
    "    |______ <b>Apple Braeburn</b>: [0_100.jpg, ..]\n",
    "    |______ <b>Apple Crimson Snow</b>: [0_100.jpg, ..] \n",
    "    ..\n",
    "    |______ <b>Apple Watermelon</b>: [0_100.jpg, ..]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***How to prepare data***\n",
    "\n",
    "Format the images into appropriately pre-processed floating point tensors before feeding to the network:\n",
    "\n",
    "1. Read images from the disk.\n",
    "2. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
    "3. Convert them into floating point tensors.\n",
    "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
    "\n",
    "Fortunately, all these tasks can be done with the `ImageDataGenerator` class provided by `tf.keras`, which can:\n",
    "* Read images and preprocess them into proper tensors. \n",
    "* Set up generators that convert these images into batches of tensors â€” helpful when training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "train_generator = ImageDataGenerator(rescale=1/255)\n",
    "val_generator = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for pre-processing and training\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "IMG_HEIGHT = 100\n",
    "IMG_WIDTH = 100\n",
    "\n",
    "num_classes = 131\n",
    "\n",
    "where_train = '/home/maihai/GitHub/Fruit-Images-Dataset/train'\n",
    "where_test  = '/home/maihai/GitHub/Fruit-Images-Dataset/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the generators, the `flow_from_directory` method will:\n",
    "* Load images from the disk,\n",
    "* Applies rescaling,\n",
    "* Applies resizes images into the required dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67692 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                               directory=where_train,\n",
    "                                               shuffle=True,\n",
    "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22688 images belonging to 131 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data_gen = val_generator.flow_from_directory(directory=where_test,\n",
    "                                        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True,\n",
    "                                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255,\n",
    "                               horizontal_flip=True,\n",
    "                               rotation_range=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The State-of-the-OLD-art: AlexNet - or CaffeNet training on 1 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet is a famous CNN architecture created in 2012 by an Ukrainian, honored by gaining the first places in contests with ImageNet database. The author trained AlexNet by 2 GPU in weeks, then develope an one-GPU version named CaffeNet. We will replicate his work in CaffeNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](caffenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 15\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "where_train = '/home/maihai/GitHub/Fruit-Images-Dataset/train'\n",
    "where_test  = '/home/maihai/GitHub/Fruit-Images-Dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "\n",
    "## Augmentation for training set only\n",
    "train_generator = ImageDataGenerator(rescale=1./255,\n",
    "                               horizontal_flip=True,\n",
    "                               rotation_range=45)\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = train_generator.flow_from_directory(directory=where_train, \n",
    "                                         target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                         class_mode='categorical',\n",
    "                                         shuffle=True,\n",
    "                                         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = val_generator.flow_from_directory(directory=where_test,\n",
    "                                        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True,\n",
    "                                        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, _ = next(train_data_gen)\n",
    "plotImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](caffenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe = Sequential([\n",
    "    # Layer 1\n",
    "    Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "\n",
    "    # Layer 2\n",
    "    Conv2D(256, kernel_size=(5, 5), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    LayerNormalization(),\n",
    "    \n",
    "    # Layer 3\n",
    "    Conv2D(384, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    LayerNormalization(),\n",
    "    \n",
    "    # Layer 4\n",
    "    Conv2D(384, kernel_size=(3, 3), activation='relu'),\n",
    "    \n",
    "    # Layer 5\n",
    "    Conv2D(256, kernel_size=(3, 3), activation='relu'), \n",
    "    \n",
    "    # Layer 6\n",
    "    Dense(4096),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    # Layer 7\n",
    "    Dense(4096),\n",
    "    \n",
    "    # Output layeres\n",
    "    Dense(1000, activation='softmax') # We have 131 classess of fruits\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The State-of-the-NEW-art: ResNet 152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ResNet 152***, published by Google in 2015. ResNet 152 as its name includes a very deep networks of 152 layers, addressing the problem of information vanishing by Resudual architecture, which skip connection while computing.\n",
    "\n",
    "ResNet was the winner of all stars in 2015, then embeded in Keras with pre-trained weighted of ***'imagenet'***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The typical transfer learning workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Workflow 1***\n",
    "\n",
    "In this project, we will use transfer learning technique to apply ResNet 152 architecture on our Fruit dataset.\n",
    "\n",
    "1. ***Instantiate*** the ResNet then load pre-trained weights.\n",
    "2. ***Freeze*** all layers by setting ResNet152.trainable = False.\n",
    "3. ***Create*** our custom layers on top of the Resnet's output.\n",
    "4. ***Train*** only our custom layers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Workflow 2***  \n",
    "\n",
    "Workflow 1 has a backdraw in my computer: out of memory. Though we marked ResNet's core layers to be skiped while training, but all of them still be loaded to memory, the number is around 60 millions. The number that big is unable for my computer to work with. So, let's try an alternative approach, much cheaper and more lightweight.  \n",
    "1. ***Instantiate*** the ResNet and load pre=trained weights.\n",
    "2. ***Run*** our Fruit dataset through it, then receive the output. This is called ***feature extraction***.\n",
    "3. ***Use*** that output as input for a new, smaller model.  \n",
    "\n",
    "By this workflow, the need for memory would highly decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fine tuning***  \n",
    "\n",
    "Either your choice is Workflow 1 or 2, afterall, we have a basical transfer-learning models, with most of weights belong to the core ResNet and a minority of our custom layers. Then, we need to adjust those ResNet weights to the Fruit dataset. The steps are follow:\n",
    "\n",
    "1. ***Unfreeze*** ResNet's core layers by setting ResNet152.trainable = True.\n",
    "2. ***Train*** the entire model, both top layers and the core.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The workflow 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet152 (Model)            (None, 4, 4, 2048)        58370944  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 131)               268419    \n",
      "=================================================================\n",
      "Total params: 58,639,363\n",
      "Trainable params: 268,419\n",
      "Non-trainable params: 58,370,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1 Instantiate\n",
    "resnet = ResNet152(weights='imagenet',\n",
    "                   input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "                   include_top=False) # to adopt our fruit classifier\n",
    "# 2 Freeze\n",
    "resnet.trainable = False\n",
    "\n",
    "# 3 Create new model on top\n",
    "inputs  = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "x       = resnet(inputs)\n",
    "x = k.layers.GlobalAveragePooling2D()(x) # Convert features of shape `resnet.output_shape[1:]` to vectors\n",
    "outputs = k.layers.Dense(num_classes)(x)\n",
    "\n",
    "resnet_copycat = Model(inputs, outputs)\n",
    "resnet_copycat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_copycat.compile(optimizer='adam',\n",
    "                       loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'Resnet_copycat_flow_1_{}'.format(int(time.time()))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 4 Training our top layers\n",
    "history = resnet_copycat.fit(train_data_gen,\n",
    "                             steps_per_epoch=67692 // batch_size,\n",
    "                             epochs=epochs,\n",
    "                             validation_data=val_data_gen,\n",
    "                             validation_steps=22688 // batch_size,\n",
    "                             callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_to_save = '/home/maihai/GitHub/Portfolio/4_Fruit_classification/resnet_copycat_flow_2'\n",
    "\n",
    "model_baseline.save(filepath=where_to_save, overwrite=False, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning of the entire model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's unfreeze the base model and train the entire model end-to-end with a low learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.trainable = True\n",
    "\n",
    "resnet_copycat.compile(optimizer='adam',\n",
    "                       loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Please, don't run this block. \n",
    "## GPU has not enough VRAM to train it.\n",
    "## CPU got 38 mins for each epoch.\n",
    "## This block is so expensive, don't run it.\n",
    "\n",
    "# Setting up TensorBoard\n",
    "NAME = 'Handmade_model_resnet_copycat_fineTune{}'.format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "# Training\n",
    "with tf.device('/cpu:0'):\n",
    "    history = resnet_copycat.fit(train_data_gen,\n",
    "                             steps_per_epoch=67692 // batch_size,\n",
    "                             epochs=epochs,\n",
    "                             validation_data=val_data_gen,\n",
    "                             validation_steps=22688 // batch_size,\n",
    "                             callbacks=[tensorboard]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
